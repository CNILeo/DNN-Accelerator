[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

简体中文 | [English](./README.md)

## 说明
本项目是个人在CNN在FPGA上进行推断的一些经验的分享，如有错误，敬请勘正。CNN在FPGA上进行推断已经算是白热化的方向了（毕竟不少厂商都流片了），奈何没有可用性较高的完全开源的Verilog代码，本项目将持续性的分享我的一些代码。

在FPGA上实现通用的CNN加速器是需要讲究软硬协同的，需要干下面这几件事。
* **CNN模型压缩**  
如量化，轻量化，融合等；CNN模型的权重默认是32位的，需要将其转换成16位甚至8位去提升运算速度（相信有一定基础的都知道相比实现整数相乘，实现浮点乘法是一件多么麻烦的事）。

* **AI编译器**  
根据CNN模型的计算层自动编译成FPGA设计好的指令集，将权重放在指定的内存地址等，这一步不是必须的，但是手动的去翻译指令集和分配内存地址极容易出错，而且耗时非常长（然而本项目并不打算涉及这一块，有兴趣的可以去了解一下ONNX和TVM）。

* **CNN模型在FPGA输入前以及输入后的一些数据处理**  
并不是所有的计算层都适合在FPGA上运行，如图片的RGB读取、Sigmoid计算层等（基本上涉及到除法且无法转换成乘法的操作都需要在CPU进行计算处理），这里的话就需要用到一些库，但是为了追求更快的速度基本上会自己造轮子（在此过程中用上SIMD、OpenMP等）

* **FPGA上的实现**  
目前无论是谷歌的TPU还是国内的寒武纪，用的都是CPU+ASIC这一种形式，即CPU负责通用性，ASIC负责专用性。本项目采用的也是CPU+ASIC结构（ZYNQ7100、X86 CPU+VU13P）。
  
这一块的工作主要有
* CPU与FPGA之间的指令交互
* CPU与FPGA之间的数据交互
* FPGA内部的数据传输  
CNN加速器的性能很大程度取决于FPGA内部数据传输的效率，毕竟计算结构就那么几种，计算结构的提速无非就是尽可能的去提升这一部分的时钟频率。
* 计算结构的设计（如脉动阵列、乘加树、FFT等）

## 文件夹说明
* **Train And Quantize CNN**  
这个文件夹是CNN模型的训练以及量化（8位数据位宽）的一些代码，以及量化工具的选择的一些经验的分享。

* **Inference**  
这个文件夹是用C/C++来实现CNN模型的推断，便于理解后续Verilog代码中的一些设计，感兴趣的也可以将这个文件夹的代码移植到HLS/Vitis，代码没有针对HLS/Vitis编写，所以编译出来的Verilog冗余代码应该会非常多。

* **FPGA**  
这个文件夹是用Verilog来实现（通用）CNN加速器，具体就是上述说的CPU与FPGA之间的指令交互、CPU与FPGA之间的数据交互、FPGA内部的数据传输以及计算结构的设计等

## 交流与反馈
如果遇到问题，可以通过Email，Issues中提问。

## 贡献者
Leo (zhsleo@outlook.com)

## 开源许可证
[MIT LICENSE](./LICENSE)