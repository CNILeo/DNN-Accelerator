# 说明
本项目是个人在CNN在FPGA上进行推断的一些经验的分享，如有错误，敬请勘正。CNN在FPGA上进行推断已经算是白热化的方向了（毕竟不少厂商都流片了），奈何没有可用性较高的完全开源的Verilog代码，本项目将持续性的分享我的一些代码。

在FPGA上实现通用的CNN加速器是需要讲究软硬协同的，需要干下面这几件事。
* CNN模型压缩
  
  如量化，轻量化，融合等；CNN模型的权重默认是32位的，需要将其转换成16位甚至8位去提升运算速度（相信有一定基础的都知道相比实现整数相乘，实现浮点乘法是一件多么麻烦的事）。
* AI编译器
 
  根据CNN模型的计算层自动编译成FPGA设计好的指令集，将权重放在指定的内存地址等，这一步不是必须的，但是手动的去翻译指令集和分配内存地址极容易出错，而且耗时非常长（然而本项目并不打算涉及这一块，有兴趣的可以去了解一下ONNX和TVM）。
* CNN模型在FPGA输入前以及输入后的一些数据处理
  
  并不是所有的计算层都适合在FPGA上运行，如图片的RGB读取、Sigmoid计算层等（基本上涉及到除法且无法转换成乘法的操作都需要在CPU进行计算处理），这里的话就需要用到一些库，但是为了追求更快的速度基本上会自己造轮子（在此过程中用上SIMD、OpenMP等）
* FPGA上的实现
 
  目前无论是谷歌的TPU还是国内的寒武纪，用的都是CPU+ASIC这一种形式，即CPU负责通用性，FPGA负责专用性。本项目采用的也是CPU+FPGA结构（ZYNQ7100、X86 CPU+VU13P）。
  
  这一块的工作主要有
  * CPU与FPGA之间的指令交互
  * CPU与FPGA之间的数据交互
  * FPGA内部的数据传输

    CNN加速器的性能很大程度取决于FPGA内部数据传输的效率，毕竟计算结构就那么几种，计算结构的提速无非就是尽可能的去提升这一部分的时钟频率。
  * 计算结构的设计（如脉动阵列、乘加树、FFT等）

# 文件夹说明
* Train And Quantize CNN

  这个文件夹是CNN模型的训练以及量化（8位数据位宽）的一些代码，以及量化工具的选择的一些经验的分享。
* Inference
  
  这个文件夹是用C/C++来实现CNN模型的推断，便于理解后续Verilog代码中的一些设计，感兴趣的也可以将这个文件夹的代码移植到HLS/Vitis，代码风格没有针对HLS/Vitis，所以编译出来的Verilog冗余代码应该会非常多，Vitis应该稍微好点，但其对代码风格的要求还是太高了。
* FPGA

  这个文件夹是用Verilog来实现（通用）CNN加速器，具体就是上述说的CPU与FPGA之间的指令交互、CPU与FPGA之间的数据交互、FPGA内部的数据传输以及计算结构的设计等

# 开源许可证
MIT LICENSE
# 联系方式


如果遇到问题，可以通过Email，Issues中提问。


本项目提供无偿适配服务，具体请与我联系商谈。
# 贡献者
Leo(Vivado@qq.com)
